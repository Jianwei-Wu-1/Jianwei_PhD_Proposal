\subsubsection{Remaining Work: Implementation and Evaluation of the Automated Descriptive Name Generation Approach}
\label{sec:remaining-work}

In the remaining work, I plan to develop an automated approach that uses a set of top-level and secondary codes produced by the selective coding in the empirical study to generate descriptive test names.
%
First, using the previously selected set of top-level and secondary codes, it is feasible for us to build the automated approach to check and improve existing test names with a uniqueness-based naming rationale.
%
Second, after the approach is completed, another empirical evaluation is also needed to further investigate the correctness, effectiveness, and comprehensibility of the approach.
%
Last, as mentioned in~\cref{sec:introduction}, the goal of my proposed research is to systematically provide descriptive test names for developers (i.e., they are based on what makes the test unique), so generating descriptive name with unique information is also needed in the automated approach.

\subsubsection{Implementation of the Concept-based Approach}

Utilizing the top-level and secondary codes that were created in the empirical study section~\cref{sec:empStudy}, it is feasible to build an automated approach that can not only improve existing test names by providing a uniqueness-based naming rationale for developers but also generate descriptive test names.
%
For the implementation, I plan to introduce the idea of formal concept analysis (FCA) as the main method, and provide how to integrate it with the top-level and secondary codes will also be explained in implementation section of our planned future work.
%
Therefore, the automated approach is also called as the concept-based approach in the rest of this proposal.
%
And I plan to follow these steps to build the concept-based approach (i.e., the automated descriptive name generation approach):
\begin{enumerate*}
    \item Implement the top-level and secondary codes
    \item Use an IDE plugin to apply the codes to the tests from a selected project
    \item After the tests are tagged, generate a list of tests - tagged text pairs
    \item Use the pairs as the input data of FCA and output the produced concept map as a metric for judging descriptive test names
    \item Check if each test name is named after what makes it unique; if is, show the tagged text to facilitate potential improvements; if not, generate descriptive test names by summarizing the unique information
    \item perform a quantitative analysis as the evaluation of the concept-based approach
\end{enumerate*}.

\subsubsection{Evaluation of the Automated Descriptive Name Generation Approach}

Research questions involved in this step are:
%
\begin{enumerate}
    \item RQ1-Correctness: Can the concept-based approach apply the top-level and secondary codes to each test correctly?
    \item RQ2-Effectiveness: Does the tagged text of each test accurately describe the uniqueness of the test?
    \item RQ3-Descriptiveness: Are the generated test names from the concept-based approach being descriptive?
\end{enumerate}.

For answering RQ1, I plan to perform a quantitative analysis by comparing the results from manual tagging of a randomly set of tests (i.e., from 5 random Java projects on Github) with the results from the concept-based approach to see if the two different results are matched.
%
For answering RQ2, I plan to further check if the tagged text that was generated by the concept-based approach is the same as the tagged text from the manual tagging from the same set of tests.
%
For answering RQ3, I plan to conduct a small-scale survey with 4 experienced developers by letting them answer a set of questions about the descriptiveness of the result that is produced by running the concept-based approach on read-world projects.


